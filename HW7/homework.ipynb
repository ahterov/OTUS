{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier(DecisionTreeClassifier):\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        # min_samples_split - The minimum number of samples required to split an internal node\n",
    "        # max_depth - The maximum depth of the tree\n",
    "        # max_features - The number of features to consider when looking for the best split:\n",
    "        #    If int, then consider max_features features at each split.\n",
    "        #    If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split.\n",
    "        #    If “sqrt”, then max_features=sqrt(n_features).\n",
    "        #    If “log2”, then max_features=log2(n_features).\n",
    "        #    If None, then max_features=n_features.\n",
    "        # sufficient_share - ?\n",
    "        # \n",
    "\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth \n",
    "        self.sufficient_share = sufficient_share \n",
    "        self.num_class = -1\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "    \n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float').reshape(1,-1)\n",
    "        r_s = r_s.astype('float').reshape(1,-1)\n",
    "        # Здесь пытался посчитать в лоб, по формуле\n",
    "        #parent_size = l_s[0][0] + r_s[0][0]\n",
    "        #gini_l = 1 - np.sum((l_c/l_s)**2, axis=1)\n",
    "        #gini_r = 1 - np.sum((r_c/r_s)**2, axis=1)\n",
    "        # Здесь чуть-чуть оптимизировал, но выигрыша в скорости это не дало :(\n",
    "        gini_l = l_s - np.sum(l_c**2, axis=1)/l_s\n",
    "        gini_r = r_s - np.sum(r_c**2, axis=1)/r_s\n",
    "        gini = gini_l.reshape(-1,1) + gini_r.reshape(-1,1)\n",
    "        return gini\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        # Здесь считаю в лоб\n",
    "        parent_size = l_s[0][0] + r_s[0][0]\n",
    "        entropy_l = np.sum((l_c/l_s)*np.log2(l_c/l_s), axis=1)\n",
    "        entropy_r = np.sum((r_c/r_s)*np.log2(r_c/r_s), axis=1)\n",
    "        entropy = (l_s/parent_size)*entropy_l.reshape(-1,1) + (r_s/parent_size)*entropy_r.reshape(-1,1)\n",
    "        return entropy\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        # Здесь считаю в лоб\n",
    "        parent_size = l_s[0][0] + r_s[0][0]\n",
    "        mc_l = 1 - np.max(l_c/l_s, axis=1)\n",
    "        mc_r = 1 - np.max(r_c/r_s, axis=1)\n",
    "        mc = (l_s/parent_size)*mc_l.reshape(-1,1) + (r_s/parent_size)*mc_r.reshape(-1,1)\n",
    "        return mc\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:round(np.sqrt(n_feature)).astype('int')]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:round(np.log2(n_feature)).astype('int')]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort() # массив индексов отсортированного массива x\n",
    "        return x[sorted_idx], y[sorted_idx] # отсортированный массив х, и, соответствующий ему, массив y \n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        # if x[i:feature_id]<threshold: left_mask[i] = True, else left_mask[i] = False\n",
    "        left_mask = x[:, feature_id] <= threshold \n",
    "        # инвертируем left_mask \n",
    "        right_mask = ~left_mask \n",
    "        # делим матрицу x и вектор y в соответствии с массивами left_mask и right_mask \n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask] \n",
    "    \n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        # 1. Сортируем вектор признака - x и, соответствующий ему, вектор целевой переменной - y\n",
    "        # 2. Сохраняем в class_number кол-во классов (кол-во уникальных значений вектора целевой переменной - y)\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # 1. Выбрасываем из вектора sorted_y по краям min_samples_split-1 элементов, так как \n",
    "        # нет смысла проверять точки разделеня признака, если в одном из детей, \n",
    "        # образованных после потенциального разделении, будет меньше, чем min_samples_split наблюдений.\n",
    "        # В оригинальном коде ДЗ было sorted_y[self.min_samples_split:-self.min_samples_split], но в этом случае\n",
    "        # алгоритм не будет рассматривать разбиения лежащие между индексами min_samples_split-1 и min_samples_split.\n",
    "        # Пример: 0 0 1 1 1 1 0 0. При min_samples_split=2. В оригинале разбиений между 1 и 2 индексом и \n",
    "        # между 5 и 6 индексом не будет, хотя, по логике они должны быть.\n",
    "        # Поэтому рассматриваем интервал min_samples_split-1:-min_samples_split+1.\n",
    "        # 2. Определяем индексы элементов, на которых происходит смена целевого класса в векторе splitted_sorted_y.\n",
    "        # Соответственно, это те точки, перед которыми надо будет проводить потенциальное разделение и считать IG. \n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split-1:-self.min_samples_split+1]\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split - 1)\n",
    "        \n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # 1. Подсчитывает по разности индексов кол-во наблюдений между сменами целевого класса (текущий индекс изменения\n",
    "        # целевого класса минус предыдущий индекс изменения целевого класса)\n",
    "        # 2. Вводим вспомогательную матрицу one_hot_code для получения кол-ва наблюдений по классам при разных разбиениях\n",
    "        # 3. Кол-во строк в one_hot_code равняется кол-ву возможных разбиений, а кол-во столбцов = кол-ву целевых классов.  \n",
    "        # Элемент one_hot_code[i][j] = 1, если при (i+1)-ом возможном разбиении мы переходим от j целевого класса\n",
    "        # ко второму целевому классу (в случаии двух целевых классов)\n",
    "        # 4. Матрица class_increments содержит кол-во элементов соответствующего целевого класса при возможных разбиениях. \n",
    "        # Элемент class_increments[i][j] = k, если при (i+1)-ом возможном разбиении кол-во элементов c целевым классом j = k\n",
    "        # 5. class_increments[0] - соответсвует кол-ву наблюдений при первом разбиении по целевым классам. \n",
    "        # Так как мы не учитывали значения целевой переменной для первых min_samples_split наблюдений, то сейчас это надо сделать.\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split-1], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), splitted_sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=class_number)\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # 1. l_class_count - кол-во наблюдений, попавших в левую часть после разбиения \n",
    "        # по возможным разбиениям (строчки) и по целевым классам (столбцы)\n",
    "        # 2. r_class_count - кол-во наблюдений, попавших в правую часть после разбиения \n",
    "        # по возможным разбиениям (строчки) и по целевым классам (столбцы)\n",
    "        # 3. l_sizes - кол-во наблюдений, попавших в левую часть после разбиения, по всем возможным разбиением (строки)\n",
    "        # 4. r_sizes - кол-во наблюдений, попавших в правую часть после разбиения, по всем возможным разбиением (строки)\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1) + 1\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # 1. Считаем выбранную функцию impurity. gs - вектор impurity по возможным разбиениям.\n",
    "        # 2. Выбираем номер разбиения, на котором имеем минимум impurity  \n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # 1. Получаем индекс точки разбиения, на котором impurity достигает минимального значения\n",
    "        # 2. Возвращаем минимальную impurity и порог разделения\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx][0], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        # Проверяем условия остановки\n",
    "        # Условие №1. Максимальное кол-во в вершине наблюдений одного из целевых класса \n",
    "        # Условие №2. Глубина дерева достигла максимального значения\n",
    "            \n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "\n",
    "        if np.bincount(y).max() >= self.sufficient_share*y.size or (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           y.size == self.min_samples_split or feature_ids.size == 0:              \n",
    "            node = [self.LEAF_TYPE, np.bincount(y).argmax(), np.bincount(y).max()/y.size]\n",
    "            return node\n",
    "        \n",
    "        impurity_min = float('+inf')\n",
    "        node = None\n",
    "        for idx in feature_ids:  \n",
    "            impurity = self.__find_threshold(x[:,idx], y)\n",
    "            if impurity[0] < impurity_min:\n",
    "                impurity_min = impurity[0]\n",
    "                threshold = impurity[1]\n",
    "                feature_id = idx\n",
    "                node = [self.NON_LEAF_TYPE, feature_id, threshold]\n",
    "                \n",
    "        if node is not None:        \n",
    "            x_l, x_r, y_l, y_r = self.__div_samples(x, y, feature_id, threshold)  \n",
    "            self.tree[2 * node_id + 1] = self.__fit_node(np.delete(x_l, feature_id, 1), y_l, 2*node_id+1, 0, depth+1)\n",
    "            self.tree[2 * node_id + 2] = self.__fit_node(np.delete(x_l, feature_id, 1), y_l, 2*node_id+2, 0, depth+1)    \n",
    "        else: node = [self.LEAF_TYPE, np.bincount(y).argmax(), np.bincount(y).max()/y.size]\n",
    "        return node\n",
    "       \n",
    "        # Ваш код\n",
    "        # Необходимо использовать следующее:\n",
    "        # self.LEAF_TYPE +\n",
    "        # self.NON_LEAF_TYPE +\n",
    "\n",
    "        # self.tree +\n",
    "        # self.max_depth +\n",
    "        # self.sufficient_share +\n",
    "        # self.min_samples_split +\n",
    "\n",
    "        # self.get_feature_ids +\n",
    "        # self.__find_threshold +\n",
    "        # self.__div_samples + \n",
    "        # self.__fit_node +\n",
    "        \n",
    "        # return self.tree\n",
    "        #pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.tree[0] = self.__fit_node(x, y, 0, 0) \n",
    "  \n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node \n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1 3 0 2]\n",
      " [5 9 2 1 6]\n",
      " [8 3 6 1 9]\n",
      " [0 4 2 6 7]\n",
      " [9 4 1 3 0]\n",
      " [6 2 6 7 2]\n",
      " [2 8 2 5 9]\n",
      " [3 1 6 0 2]] [1 0 1 1 1 1 0 0]\n",
      "[1 9 3 4 4 2 8 1]\n",
      "sorted_x= [1 1 2 3 4 4 8 9]\n",
      "sorted_y= [1 0 1 1 1 1 0 0]\n",
      "class_number= 2\n",
      "splitted_sorted_y= [0 1 1 1 1 0]\n",
      "r_border_ids= [1 5]\n",
      "eq_el_count= [0 4]\n",
      "one_hot_code= [[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "sorted_y[r_border_ids - 1]= [1 1]\n",
      "one_hot_code= [[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "eq_el_count.reshape(-1, 1)= [[0]\n",
      " [4]]\n",
      "class_increments= [[ 0.  0.]\n",
      " [ 0.  4.]]\n",
      "[1 1]\n",
      "class_increments= [[ 1.  1.]\n",
      " [ 0.  4.]]\n",
      "l_class_count= [[ 1.  1.]\n",
      " [ 1.  5.]]\n",
      "r_class_count= [[ 2.  4.]\n",
      " [ 2.  0.]]\n",
      "l_sizes= [[2]\n",
      " [6]]\n",
      "r_sizes= [[6]\n",
      " [2]]\n",
      "parent_size= 8.0\n",
      "gini_l= [ 0.5         0.27777778]\n",
      "gini_r= [ 0.44444444  0.        ]\n",
      "l_s/parent_size= [[ 0.25]\n",
      " [ 0.75]]\n",
      "(l_s/parent_size)*gini_l= [[ 0.125     ]\n",
      " [ 0.20833333]]\n",
      "gs= [[ 0.45833333]\n",
      " [ 0.20833333]]\n",
      "idx= 1\n",
      "left_el_id= 6\n",
      "gs[idx]= [ 0.20833333]\n",
      "6.0\n",
      "[4 5 8 0 9 6 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Тут разбор кода. Смотреть не надо\n",
    "x = np.array([[4,1,3,0,2],[5,9,2,1,6],[8,3,6,1,9],[0,4,2,6,7],[9,4,1,3,0],[6,2,6,7,2],[2,8,2,5,9],[3,1,6,0,2]])\n",
    "y = np.array([1,0,1,1,1,1,0,0])\n",
    "min_samples_split = 2\n",
    "print(x,y)\n",
    "feature = x[:,1]\n",
    "print(feature)\n",
    "sorted_idx = feature.argsort()\n",
    "sorted_x, sorted_y = feature[sorted_idx], y[sorted_idx]\n",
    "print(\"sorted_x=\", sorted_x)\n",
    "print(\"sorted_y=\", sorted_y)\n",
    "class_number = np.unique(y).shape[0]\n",
    "print(\"class_number=\",class_number)\n",
    "splitted_sorted_y = sorted_y[min_samples_split-1:-min_samples_split+1]\n",
    "r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (min_samples_split - 1)\n",
    "print(\"splitted_sorted_y=\", splitted_sorted_y)\n",
    "print(\"r_border_ids=\", r_border_ids)\n",
    "\n",
    "eq_el_count = r_border_ids - np.append([min_samples_split-1], r_border_ids[:-1])\n",
    "print(\"eq_el_count=\",eq_el_count)\n",
    "one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "print(\"one_hot_code=\",one_hot_code)\n",
    "print(\"sorted_y[r_border_ids - 1]=\",sorted_y[r_border_ids - 1])\n",
    "one_hot_code[np.arange(r_border_ids.shape[0]), splitted_sorted_y[r_border_ids - 1]] = 1\n",
    "print(\"one_hot_code=\",one_hot_code)\n",
    "print(\"eq_el_count.reshape(-1, 1)=\",eq_el_count.reshape(-1, 1))\n",
    "class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "print(\"class_increments=\",class_increments)\n",
    "class_increments[0] = class_increments[0] + np.bincount(sorted_y[:min_samples_split], minlength=class_number)\n",
    "print(np.bincount(sorted_y[:min_samples_split], minlength=class_number))\n",
    "print(\"class_increments=\",class_increments)\n",
    "\n",
    "l_class_count = np.cumsum(class_increments, axis=0)\n",
    "print('l_class_count=',l_class_count)\n",
    "r_class_count = np.bincount(y) - l_class_count\n",
    "print('r_class_count=',r_class_count)\n",
    "l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1) + 1\n",
    "print('l_sizes=',l_sizes)\n",
    "r_sizes = sorted_y.shape[0] - l_sizes\n",
    "print('r_sizes=',r_sizes)\n",
    "\n",
    "def __gini(l_c, l_s, r_c, r_s):\n",
    "    l_s = l_s.astype('float')\n",
    "    r_s = r_s.astype('float')\n",
    "    parent_size = l_s[0][0] + r_s[0][0]\n",
    "    print(\"parent_size=\",parent_size)\n",
    "    gini_l = 1 - np.sum((l_c/l_s)**2, axis=1)\n",
    "    print(\"gini_l=\",gini_l)\n",
    "    gini_r = 1 - np.sum((r_c/r_s)**2, axis=1)\n",
    "    print(\"gini_r=\",gini_r)\n",
    "    print(\"l_s/parent_size=\",l_s/parent_size)\n",
    "    print(\"(l_s/parent_size)*gini_l=\",(l_s/parent_size)*gini_l.reshape(-1,1))\n",
    "    gini = (l_s/parent_size)*gini_l.reshape(-1,1) + (r_s/parent_size)*gini_r.reshape(-1,1)\n",
    "    return gini\n",
    "gs = __gini(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "print(\"gs=\", gs)\n",
    "idx = np.argmin(gs)\n",
    "print (\"idx=\", idx)\n",
    "left_el_id = l_sizes[idx][0]\n",
    "print(\"left_el_id=\",left_el_id)\n",
    "print(\"gs[idx]=\",gs[idx])\n",
    "print((sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0)\n",
    "print(x[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 120269 entries, 1 to 150000\n",
      "Data columns (total 11 columns):\n",
      "SeriousDlqin2yrs                        120269 non-null int64\n",
      "RevolvingUtilizationOfUnsecuredLines    120269 non-null float64\n",
      "age                                     120269 non-null int64\n",
      "NumberOfTime30-59DaysPastDueNotWorse    120269 non-null int64\n",
      "DebtRatio                               120269 non-null float64\n",
      "MonthlyIncome                           120269 non-null float64\n",
      "NumberOfOpenCreditLinesAndLoans         120269 non-null int64\n",
      "NumberOfTimes90DaysLate                 120269 non-null int64\n",
      "NumberRealEstateLoansOrLines            120269 non-null int64\n",
      "NumberOfTime60-89DaysPastDueNotWorse    120269 non-null int64\n",
      "NumberOfDependents                      120269 non-null float64\n",
      "dtypes: float64(4), int64(7)\n",
      "memory usage: 11.0 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "1                 1                              0.766127   45   \n",
       "2                 0                              0.957151   40   \n",
       "3                 0                              0.658180   38   \n",
       "4                 0                              0.233810   30   \n",
       "5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "1                                     2   0.802982         9120.0   \n",
       "2                                     0   0.121876         2600.0   \n",
       "3                                     1   0.085113         3042.0   \n",
       "4                                     0   0.036050         3300.0   \n",
       "5                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "1                               13                        0   \n",
       "2                                4                        0   \n",
       "3                                2                        1   \n",
       "4                                5                        0   \n",
       "5                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "1                             6                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             0                                     0   \n",
       "5                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "1                 2.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "5                 0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0]).astype('int32')\n",
    "#np.unique(df[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.573514223098755\n",
      "2.200439929962158\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Со скоростью проблемы! Не очень понимаю, где можно оптимизировать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9307391702\n",
      "0.928244782573\n",
      "0.931778498379\n",
      "0.929658268895\n",
      "0.932149835779\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]   \n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89394695269\n",
      "0.889082896815\n",
      "0.892450320113\n",
      "0.891535711316\n",
      "0.889327734586\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Зато с качеством чуть лучше, чем у sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', na_values='NaN')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    return df.drop(labels = ['PassengerId', 'Embarked', 'Cabin', 'Name', 'Ticket'], axis=1)\n",
    "\n",
    "def get_sex(df):\n",
    "    df.set_value(df.Sex == 'male','Sex',1)\n",
    "    df.set_value(df.Sex == 'female','Sex',0)\n",
    "    return df\n",
    "\n",
    "def split_sibsp(df):   \n",
    "    Sib = np.zeros(len(df.SibSp))\n",
    "    Sp = np.zeros(len(df.SibSp))\n",
    "    for passenger in df.iterrows():    \n",
    "        if passenger[1]['SibSp']>=2: \n",
    "            Sib[passenger[0]]=passenger[1]['SibSp']\n",
    "            continue\n",
    "\n",
    "        if (passenger[1]['SibSp']==1) and (passenger[1]['Sex']=='female') and (passenger[1]['Name'].find('Miss')!=-1):\n",
    "            Sib[passenger[0]]=1\n",
    "            continue        \n",
    "\n",
    "        if (passenger[1]['SibSp']==1) and (passenger[1]['Sex']=='female') and (passenger[1]['Name'].find('Mrs')!=-1):\n",
    "            surname = passenger[1]['Name'].split(',')[0]\n",
    "            Find = False\n",
    "            for pas in df.iterrows():\n",
    "                if (pas[1]['Name'].startswith(surname + ',')) and (pas[1]['SibSp']==1) and \\\n",
    "                   (pas[1]['Name'].find('Mr')!=-1) and (pas[1]['Ticket']==passenger[1]['Ticket']):\n",
    "                    Sp[passenger[0]] = 1\n",
    "                    Find = True\n",
    "                    break\n",
    "            if Find is not True: Sib[passenger[0]] = 1\n",
    "            continue\n",
    "\n",
    "        if (passenger[1]['SibSp']==1) and (passenger[1]['Sex']=='male') and (passenger[1]['Name'].find('Mr')!=-1):\n",
    "            surname = passenger[1]['Name'].split(',')[0]\n",
    "            Find = False\n",
    "            for pas in df.iterrows():\n",
    "                if (pas[1]['Name'].startswith(surname + ',')) and (pas[1]['SibSp']==1) and \\\n",
    "                   (pas[1]['Name'].find('Mrs')!=-1) and (pas[1]['Ticket']==passenger[1]['Ticket']):\n",
    "                    Sp[passenger[0]] = 1\n",
    "                    Find = True\n",
    "                    break\n",
    "            if Find is not True: Sib[passenger[0]] = 1   \n",
    "            continue\n",
    "\n",
    "    df['Sib'] = Sib\n",
    "    df['Sp'] = Sp\n",
    "    return df\n",
    "\n",
    "def set_age(df1):\n",
    "    child_mean = int(df1.loc[df1.Age<=12]['Age'].mean())\n",
    "    adult_mean = int(df1.loc[df1.Age>12]['Age'].mean())\n",
    "    \n",
    "    for passenger in df1.loc[pd.isnull(df1['Age'])].iterrows():\n",
    "        surname = passenger[1]['Name'].split(',')[0]    \n",
    "        if passenger[1]['Sib']>0:     \n",
    "            namesakes_age = []\n",
    "            for pas in df1.iterrows():         \n",
    "                if (pas[1]['Name'].startswith(surname + ',')) and \\\n",
    "                   (pas[1]['Sib']==passenger[1]['Sib']) and \\\n",
    "                   (pas[1]['Ticket']==passenger[1]['Ticket']) and \\\n",
    "                   (pd.isnull(pas[1]['Age']) is not True): \n",
    "                        namesakes_age.append(pas[1]['Age'])\n",
    "\n",
    "            if len(namesakes_age)>0: df1.set_value(passenger[0],'Age', int(np.array(namesakes_age).mean())) \n",
    "            else: df1.set_value(passenger[0],'Age', child_mean)\n",
    "\n",
    "        if passenger[1]['Sp']>0:\n",
    "            for pas in df1.iterrows(): \n",
    "                if (pas[1]['Name'].startswith(surname + ',')) and (pas[1]['Sp']==passenger[1]['Sp']) and \\\n",
    "                   (pas[1]['Ticket']==passenger[1]['Ticket']) and (isinstance(pas[1]['Age'], float)):\n",
    "                        df1.set_value(passenger[0],'Age', pas[1]['Age'])\n",
    "                else: df1.set_value(passenger[0],'Age', adult_mean)\n",
    "\n",
    "        if passenger[1]['Sp']==0 and passenger[1]['Sib']==0: \n",
    "            df1.set_value(passenger[0],'Age', adult_mean)\n",
    "    return df1\n",
    "\n",
    "def drop_columns2(df):\n",
    "    return df.drop(labels = ['Sib', 'Sp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(FunctionTransformer(split_sibsp, validate=False), \\\n",
    "                         FunctionTransformer(set_age, validate=False), \\\n",
    "                         FunctionTransformer(get_sex, validate=False), \\\n",
    "                         FunctionTransformer(drop_columns, validate=False), \\\n",
    "                         FunctionTransformer(drop_columns2, validate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass Sex   Age  SibSp  Parch     Fare\n",
       "0         0       3   1  22.0      1      0   7.2500\n",
       "1         1       1   0  38.0      1      0  71.2833\n",
       "2         1       3   0  26.0      0      0   7.9250\n",
       "3         1       1   0  35.0      1      0  53.1000\n",
       "4         0       3   1  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pipeline.fit_transform(df)\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "dtypes: float64(2), int64(4), object(1)\n",
      "memory usage: 45.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = dff.as_matrix(columns=dff.columns[1:])\n",
    "y = dff.as_matrix(columns=dff.columns[:1])\n",
    "y = y.reshape(y.shape[0]).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Таким вот идиотским способом реализовал подбор параметров по сетке, так как RandomizeSearchCV и GridSearchCV \n",
    "# требуют в качестве estimator'а объект sklearn. А при наследовании от DecisionTreeClassifier ругается на параметр criterion\n",
    "# при инициации.\n",
    "n_splits = 5\n",
    "gkf = KFold(n_splits=n_splits, shuffle=True)\n",
    "all_accuracy = []\n",
    "for min_samples_split in range(1,4):\n",
    "    for max_depth in range(2,11):\n",
    "        accuracy = []\n",
    "        for train, test in gkf.split(x, y):\n",
    "            X_train, y_train = x[train], y[train]\n",
    "            X_test, y_test = x[test], y[test] \n",
    "            my_clf = MyDecisionTreeClassifier(min_samples_split=min_samples_split, max_depth=max_depth)\n",
    "            my_clf.fit(X_train, y_train)\n",
    "            accuracy.append(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))\n",
    "        all_accuracy.append([np.mean(accuracy),min_samples_split,max_depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = 0.616226225598 min_samples_split = 1 max_depth = 7\n"
     ]
    }
   ],
   "source": [
    "error, min_samples_split, max_depth = all_accuracy[np.argmax(all_accuracy, axis=0)[0]]\n",
    "print(\"error =\", error, \"min_samples_split =\", min_samples_split, \"max_depth =\", max_depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
